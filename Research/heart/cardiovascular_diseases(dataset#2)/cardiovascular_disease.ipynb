{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Summary"
      ],
      "metadata": {
        "id": "CwAUmnqL1G6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBQjchWe0LXi",
        "outputId": "d9cbec37-116d-4111-cb07-720ab5dde0e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Shape': (1000, 14),\n",
              " 'Columns': ['patientid',\n",
              "  'age',\n",
              "  'gender',\n",
              "  'chestpain',\n",
              "  'restingBP',\n",
              "  'serumcholestrol',\n",
              "  'fastingbloodsugar',\n",
              "  'restingrelectro',\n",
              "  'maxheartrate',\n",
              "  'exerciseangia',\n",
              "  'oldpeak',\n",
              "  'slope',\n",
              "  'noofmajorvessels',\n",
              "  'target'],\n",
              " 'Data Types': {'patientid': dtype('int64'),\n",
              "  'age': dtype('int64'),\n",
              "  'gender': dtype('int64'),\n",
              "  'chestpain': dtype('int64'),\n",
              "  'restingBP': dtype('int64'),\n",
              "  'serumcholestrol': dtype('int64'),\n",
              "  'fastingbloodsugar': dtype('int64'),\n",
              "  'restingrelectro': dtype('int64'),\n",
              "  'maxheartrate': dtype('int64'),\n",
              "  'exerciseangia': dtype('int64'),\n",
              "  'oldpeak': dtype('float64'),\n",
              "  'slope': dtype('int64'),\n",
              "  'noofmajorvessels': dtype('int64'),\n",
              "  'target': dtype('int64')},\n",
              " 'Missing Values': {'patientid': 0,\n",
              "  'age': 0,\n",
              "  'gender': 0,\n",
              "  'chestpain': 0,\n",
              "  'restingBP': 0,\n",
              "  'serumcholestrol': 0,\n",
              "  'fastingbloodsugar': 0,\n",
              "  'restingrelectro': 0,\n",
              "  'maxheartrate': 0,\n",
              "  'exerciseangia': 0,\n",
              "  'oldpeak': 0,\n",
              "  'slope': 0,\n",
              "  'noofmajorvessels': 0,\n",
              "  'target': 0},\n",
              " 'Sample Data':    patientid  age  gender  chestpain  restingBP  serumcholestrol  \\\n",
              " 0     103368   53       1          2        171                0   \n",
              " 1     119250   40       1          0         94              229   \n",
              " 2     119372   49       1          2        133              142   \n",
              " 3     132514   43       1          0        138              295   \n",
              " 4     146211   31       1          1        199                0   \n",
              " \n",
              "    fastingbloodsugar  restingrelectro  maxheartrate  exerciseangia  oldpeak  \\\n",
              " 0                  0                1           147              0      5.3   \n",
              " 1                  0                1           115              0      3.7   \n",
              " 2                  0                0           202              1      5.0   \n",
              " 3                  1                1           153              0      3.2   \n",
              " 4                  0                2           136              0      5.3   \n",
              " \n",
              "    slope  noofmajorvessels  target  \n",
              " 0      3                 3       1  \n",
              " 1      1                 1       0  \n",
              " 2      1                 0       0  \n",
              " 3      2                 2       1  \n",
              " 4      3                 2       1  }"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Cardiovascular_Disease_Dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "dataset_info = {\n",
        "    \"Shape\": data.shape,\n",
        "    \"Columns\": data.columns.tolist(),\n",
        "    \"Data Types\": data.dtypes.to_dict(),\n",
        "    \"Missing Values\": data.isnull().sum().to_dict(),\n",
        "    \"Sample Data\": data.head()\n",
        "}\n",
        "\n",
        "dataset_info\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['patientid', 'target'])  # Dropping 'patientid' as it's irrelevant\n",
        "y = data['target']\n",
        "\n",
        "# Encoding categorical columns if any (like 'gender', 'chestpain', etc.)\n",
        "categorical_columns = ['gender', 'chestpain', 'fastingbloodsugar', 'restingrelectro', 'exerciseangia', 'slope']\n",
        "X[categorical_columns] = X[categorical_columns].apply(LabelEncoder().fit_transform)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Prepare a template for machine learning models\n",
        "model_code = \"\"\"\n",
        "# Template for implementing machine learning models\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Example Model (Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\\\n\", classification_report(y_test, y_pred))\n",
        "\"\"\"\n",
        "\n",
        "# Display preprocessed data details and code\n",
        "{\n",
        "    \"Processed Feature Shape\": X_train_scaled.shape,\n",
        "    \"Code Template\": model_code\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJYDFDzb1a4c",
        "outputId": "e4ca42b6-ce49-4f79-ee85-2d447da99253"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Processed Feature Shape': (800, 12),\n",
              " 'Code Template': '\\n# Template for implementing machine learning models\\n\\nfrom sklearn.metrics import classification_report, accuracy_score\\n\\n# Example Model (Logistic Regression)\\nfrom sklearn.linear_model import LogisticRegression\\n\\n# Initialize the model\\nmodel = LogisticRegression()\\n\\n# Train the model\\nmodel.fit(X_train_scaled, y_train)\\n\\n# Predict on the test set\\ny_pred = model.predict(X_test_scaled)\\n\\n# Evaluate the model\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Classification Report:\\\\n\", classification_report(y_test, y_pred))\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementing a Logistic Regression model:"
      ],
      "metadata": {
        "id": "uad8fqlq2KyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Template for implementing machine learning models\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Example Model (Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-hnRhkI10Rv",
        "outputId": "1b4ce941-e022-43f4-c66c-d108f253275c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.965\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96        83\n",
            "           1       0.97      0.97      0.97       117\n",
            "\n",
            "    accuracy                           0.96       200\n",
            "   macro avg       0.96      0.96      0.96       200\n",
            "weighted avg       0.96      0.96      0.96       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest, Support Vector Machine (SVM), and a simple Neural Network"
      ],
      "metadata": {
        "id": "-6nRjvO72ocv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "rf_pred = rf_model.predict(X_test_scaled)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "svm_pred = svm_model.predict(X_test_scaled)\n",
        "print(\"\\nSVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred))\n",
        "\n",
        "# Neural Network\n",
        "nn_model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
        "nn_model.fit(X_train_scaled, y_train)\n",
        "nn_pred = nn_model.predict(X_test_scaled)\n",
        "print(\"\\nNeural Network Accuracy:\", accuracy_score(y_test, nn_pred))\n",
        "print(\"Neural Network Classification Report:\\n\", classification_report(y_test, nn_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXDo4xp02Ss3",
        "outputId": "db6406ac-8e0c-4477-d095-8796726b1ad7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.99\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        83\n",
            "           1       0.98      1.00      0.99       117\n",
            "\n",
            "    accuracy                           0.99       200\n",
            "   macro avg       0.99      0.99      0.99       200\n",
            "weighted avg       0.99      0.99      0.99       200\n",
            "\n",
            "\n",
            "SVM Accuracy: 0.96\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        83\n",
            "           1       0.97      0.97      0.97       117\n",
            "\n",
            "    accuracy                           0.96       200\n",
            "   macro avg       0.96      0.96      0.96       200\n",
            "weighted avg       0.96      0.96      0.96       200\n",
            "\n",
            "\n",
            "Neural Network Accuracy: 0.975\n",
            "Neural Network Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97        83\n",
            "           1       0.99      0.97      0.98       117\n",
            "\n",
            "    accuracy                           0.97       200\n",
            "   macro avg       0.97      0.98      0.97       200\n",
            "weighted avg       0.98      0.97      0.98       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature selection and hyperparameter tuning"
      ],
      "metadata": {
        "id": "5D_pNVi7359y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# ====================\n",
        "# Step 1: Feature Selection\n",
        "# ====================\n",
        "\n",
        "# Train a preliminary Random Forest model\n",
        "feature_selector = RandomForestClassifier(random_state=42)\n",
        "feature_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get feature importances and select top features\n",
        "importances = feature_selector.feature_importances_\n",
        "selected_features = SelectFromModel(feature_selector, threshold=\"mean\")\n",
        "X_train_selected = selected_features.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selected_features.transform(X_test_scaled)\n",
        "\n",
        "# Feature Names\n",
        "selected_columns = X.columns[selected_features.get_support()]\n",
        "print(\"Selected Features:\", selected_columns.tolist())\n",
        "\n",
        "# ====================\n",
        "# Step 2: Hyperparameter Tuning\n",
        "# ====================\n",
        "\n",
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Perform the grid search\n",
        "grid_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# Best Parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# ====================\n",
        "# Step 3: Final Model Evaluation\n",
        "# ====================\n",
        "\n",
        "# Train the final model with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = best_model.predict(X_test_selected)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Results\n",
        "print(\"Optimized Random Forest Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5KxAGhd36tq",
        "outputId": "f5352c87-6fa5-4719-df89-ba1ea37efd24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['chestpain', 'restingBP', 'slope']\n",
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "Best Parameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Optimized Random Forest Accuracy: 0.95\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94        83\n",
            "           1       0.97      0.94      0.96       117\n",
            "\n",
            "    accuracy                           0.95       200\n",
            "   macro avg       0.95      0.95      0.95       200\n",
            "weighted avg       0.95      0.95      0.95       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k-fold cross-validation"
      ],
      "metadata": {
        "id": "vvlakPgu6P5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_scores = cross_val_score(rf_model, X_train_selected, y_train, cv=5)\n",
        "print(\"Cross-validation scores:\", cross_val_scores)\n",
        "print(\"Average cross-validation score:\", np.mean(cross_val_scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-zROboE6Q8w",
        "outputId": "c962eca8-c159-4eb2-bde5-9a435b5e3264"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.975   0.96875 0.94375 0.95    0.94375]\n",
            "Average cross-validation score: 0.95625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Explainability"
      ],
      "metadata": {
        "id": "kFzkAFHN6abx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(rf_model, 'final_random_forest_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVTrSb_56bMq",
        "outputId": "9e05a214-a3d8-48f2-e4ee-584fba69ce86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['final_random_forest_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC8qkZ5J9oeF",
        "outputId": "44340b60-7d22-41a5-bef2-754d8bf316dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.46.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.6)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "model = joblib.load('final_random_forest_model.pkl')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    prediction = model.predict([data['features']])\n",
        "    return jsonify({'prediction': prediction.tolist()})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCmun-SB_c8e",
        "outputId": "a39f7da3-9bee-401f-e858-892b6d25b364"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sM3mNZuU_rsQ",
        "outputId": "dd23cd81-d148-4b30-ba7b-0ba96afc72fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.7.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.5.0 (from gradio)\n",
            "  Downloading gradio_client-1.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.0->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.5.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.7.1-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.7.1 gradio-client-1.5.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.1 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              },
              "id": "f64aa6ce28494031a86455b243b4e8e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "# Assuming your dataset is already loaded into a DataFrame called `df`\n",
        "df = pd.read_csv('Cardiovascular_Disease_Dataset.csv')\n",
        "\n",
        "# Get a list of features (column names) and their data types\n",
        "feature_info = df.dtypes\n",
        "\n",
        "# Display feature names and their corresponding data types\n",
        "print(feature_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj7fRb88BQnO",
        "outputId": "f3fa0d9b-b745-4f86-87d6-37145da7d550"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patientid              int64\n",
            "age                    int64\n",
            "gender                 int64\n",
            "chestpain              int64\n",
            "restingBP              int64\n",
            "serumcholestrol        int64\n",
            "fastingbloodsugar      int64\n",
            "restingrelectro        int64\n",
            "maxheartrate           int64\n",
            "exerciseangia          int64\n",
            "oldpeak              float64\n",
            "slope                  int64\n",
            "noofmajorvessels       int64\n",
            "target                 int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import joblib\n",
        "\n",
        "# Load the trained Random Forest model\n",
        "model = joblib.load('final_random_forest_model.pkl')\n",
        "\n",
        "# Define the function for prediction\n",
        "def predict(age, gender, chestpain, restingBP, serumcholestrol, fastingbloodsugar,\n",
        "            restingrelectro, maxheartrate, exerciseangia, oldpeak, slope,\n",
        "            noofmajorvessels):\n",
        "    # Collecting the input features into a list for prediction\n",
        "    features = [age, gender, chestpain, restingBP, serumcholestrol, fastingbloodsugar,\n",
        "                restingrelectro, maxheartrate, exerciseangia, oldpeak, slope,\n",
        "                noofmajorvessels]\n",
        "    prediction = model.predict([features])\n",
        "    return prediction[0]\n",
        "\n",
        "# Create the Gradio interface for the features\n",
        "iface = gr.Interface(\n",
        "    fn=predict,  # Function to call for prediction\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Age\"),  # Numeric input for age\n",
        "        gr.Dropdown(label=\"Gender\", choices=[0, 1], type=\"value\"),  # Assuming gender is encoded as 0/1\n",
        "        gr.Dropdown(label=\"Chest Pain\", choices=[0, 1, 2, 3], type=\"value\"),  # Example for chest pain type\n",
        "        gr.Number(label=\"Resting Blood Pressure\"),  # Numeric input\n",
        "        gr.Number(label=\"Serum Cholesterol\"),  # Numeric input\n",
        "        gr.Dropdown(label=\"Fasting Blood Sugar\", choices=[0, 1], type=\"value\"),  # 0 or 1\n",
        "        gr.Dropdown(label=\"Resting Electrocardiographic Results\", choices=[0, 1, 2], type=\"value\"),  # Example choices\n",
        "        gr.Number(label=\"Max Heart Rate\"),  # Numeric input\n",
        "        gr.Dropdown(label=\"Exercise Angina\", choices=[0, 1], type=\"value\"),  # 0 or 1 for exercise angina\n",
        "        gr.Number(label=\"Old Peak (Depression of ST segment)\"),  # Numeric input\n",
        "        gr.Dropdown(label=\"Slope of the Peak Exercise ST Segment\", choices=[0, 1, 2], type=\"value\"),  # Example choices\n",
        "        gr.Dropdown(label=\"Number of Major Vessels Colored by Fluoroscopy\", choices=[0, 1, 2, 3], type=\"value\")  # Example choices\n",
        "    ],\n",
        "    outputs=\"text\",  # Text output for the prediction\n",
        "    live=True,  # Live prediction as the user types\n",
        "    title=\"Cardiovascular Disease Prediction\",  # Title of the application\n",
        "    description=\"Enter the feature values to predict the presence of cardiovascular disease.\"  # Description\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "V8AaG07N_8lL",
        "outputId": "68ddb016-52d7-467d-cfbc-205ad1566ce7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5d6e63063ce669467f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5d6e63063ce669467f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5d6e63063ce669467f.gradio.live\n"
          ]
        }
      ]
    }
  ]
}