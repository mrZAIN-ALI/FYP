{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10338,"databundleVersionId":862042,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Import libraries and set seeds for reproducibility.\nimport os\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pydicom\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\n\n# Set seeds for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nprint(\"✅ Libraries imported and seeds set!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:07.332402Z","iopub.execute_input":"2025-03-23T22:07:07.332766Z","iopub.status.idle":"2025-03-23T22:07:07.339068Z","shell.execute_reply.started":"2025-03-23T22:07:07.332736Z","shell.execute_reply":"2025-03-23T22:07:07.337888Z"}},"outputs":[{"name":"stdout","text":"✅ Libraries imported and seeds set!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 2: Load dataset metadata and split data into training and validation sets.\ndataset_path = \"/kaggle/input/rsna-pneumonia-detection-challenge\"\ntrain_labels_csv = os.path.join(dataset_path, \"stage_2_train_labels.csv\")\nclass_info_csv = os.path.join(dataset_path, \"stage_2_detailed_class_info.csv\")\n\n# Read CSV files\nlabels_df = pd.read_csv(train_labels_csv)\nclass_info_df = pd.read_csv(class_info_csv)\n\n# Merge on 'patientId' and simplify labels (0: Normal, 1: Pneumonia)\nmerged_df = pd.merge(labels_df, class_info_df, on=\"patientId\")\nlabels_simple = merged_df[['patientId', 'Target']].drop_duplicates().reset_index(drop=True)\nlabels_simple['Target'] = labels_simple['Target'].map({0: 'Normal', 1: 'Pneumonia'})\nlabels_simple['patientId'] = labels_simple['patientId'].astype(str) + \".dcm\"\n\n# Split data (80% train, 20% validation), stratified by target.\ntrain_df, val_df = train_test_split(labels_simple, test_size=0.2, random_state=SEED, stratify=labels_simple['Target'])\nprint(\"Train samples:\", len(train_df))\nprint(\"Validation samples:\", len(val_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:07.340376Z","iopub.execute_input":"2025-03-23T22:07:07.340739Z","iopub.status.idle":"2025-03-23T22:07:07.555219Z","shell.execute_reply.started":"2025-03-23T22:07:07.340688Z","shell.execute_reply":"2025-03-23T22:07:07.554449Z"}},"outputs":[{"name":"stdout","text":"Train samples: 21347\nValidation samples: 5337\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 3: Define a function to load and preprocess DICOM images.\ndef load_preprocess_dicom(dicom_path, img_size=(240,240)):\n    dicom_data = pydicom.dcmread(dicom_path)\n    img_array = dicom_data.pixel_array.astype(np.float32)\n    # Normalize pixel values to [0,1]\n    img_norm = (img_array - np.min(img_array)) / (np.max(img_array) - np.min(img_array) + 1e-10)\n    # Resize image\n    img_resized = cv2.resize(img_norm, img_size)\n    # Convert grayscale to 3-channel RGB\n    img_rgb = np.stack([img_resized]*3, axis=-1)\n    return img_rgb\n\n# Test the function on a sample image\nsample_image_path = os.path.join(dataset_path, \"stage_2_train_images\", train_df.iloc[0]['patientId'])\nsample_img = load_preprocess_dicom(sample_image_path)\nprint(\"✅ Sample image shape (should be 240x240x3):\", sample_img.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:07.556993Z","iopub.execute_input":"2025-03-23T22:07:07.557223Z","iopub.status.idle":"2025-03-23T22:07:07.663175Z","shell.execute_reply.started":"2025-03-23T22:07:07.557203Z","shell.execute_reply":"2025-03-23T22:07:07.662443Z"}},"outputs":[{"name":"stdout","text":"✅ Sample image shape (should be 240x240x3): (240, 240, 3)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Cell 4: Create data generators for training and validation.\ndef data_generator(df, batch_size=64, img_size=(240,240), infinite=True):\n    def gen():\n        if infinite:\n            while True:\n                shuffled_df = df.sample(frac=1).reset_index(drop=True)\n                for _, row in shuffled_df.iterrows():\n                    patient_id = row['patientId']\n                    label = 1 if row['Target'] == 'Pneumonia' else 0\n                    dicom_path = os.path.join(dataset_path, \"stage_2_train_images\", patient_id)\n                    img = load_preprocess_dicom(dicom_path, img_size)\n                    yield img, label\n        else:\n            for _, row in df.iterrows():\n                patient_id = row['patientId']\n                label = 1 if row['Target'] == 'Pneumonia' else 0\n                dicom_path = os.path.join(dataset_path, \"stage_2_train_images\", patient_id)\n                img = load_preprocess_dicom(dicom_path, img_size)\n                yield img, label\n\n    ds = tf.data.Dataset.from_generator(\n        gen,\n        output_types=(tf.float32, tf.int32),\n        output_shapes=((img_size[0], img_size[1], 3), ())\n    )\n    ds = ds.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return ds\n\nBATCH_SIZE = 64\ntrain_ds = data_generator(train_df, batch_size=BATCH_SIZE, img_size=(240,240), infinite=True)\nval_ds = data_generator(val_df, batch_size=BATCH_SIZE, img_size=(240,240), infinite=False)\nprint(\"✅ Data generators created with batch size:\", BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:07.664587Z","iopub.execute_input":"2025-03-23T22:07:07.664933Z","iopub.status.idle":"2025-03-23T22:07:10.197532Z","shell.execute_reply.started":"2025-03-23T22:07:07.664908Z","shell.execute_reply":"2025-03-23T22:07:10.196753Z"}},"outputs":[{"name":"stdout","text":"✅ Data generators created with batch size: 64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 5: Compute class weights to mitigate class imbalance.\ny_train = train_df['Target'].apply(lambda x: 1 if x == 'Pneumonia' else 0)\nweights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = {i: w for i, w in enumerate(weights)}\nprint(\"✅ Class weights computed:\", class_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:10.198375Z","iopub.execute_input":"2025-03-23T22:07:10.198690Z","iopub.status.idle":"2025-03-23T22:07:10.216964Z","shell.execute_reply.started":"2025-03-23T22:07:10.198658Z","shell.execute_reply":"2025-03-23T22:07:10.216254Z"}},"outputs":[{"name":"stdout","text":"✅ Class weights computed: {0: 0.6454314567333858, 1: 2.219022869022869}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 6: Install Keras Tuner (if not already installed)\n!pip install -q keras-tuner\nimport keras_tuner as kt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:10.217793Z","iopub.execute_input":"2025-03-23T22:07:10.218003Z","iopub.status.idle":"2025-03-23T22:07:14.728175Z","shell.execute_reply.started":"2025-03-23T22:07:10.217985Z","shell.execute_reply":"2025-03-23T22:07:14.727058Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Cell 7: Define the model building function for hyperparameter tuning.\ndef build_model(hp):\n    from tensorflow.keras.applications import DenseNet201\n    from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n    from tensorflow.keras.models import Model\n\n    # Load DenseNet201 with ImageNet weights (without the top classifier)\n    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(240,240,3))\n    \n    # Hyperparameter to decide whether to unfreeze the base or not\n    unfreeze = hp.Boolean('unfreeze', default=True)\n    if unfreeze:\n        base_model.trainable = True\n    else:\n        base_model.trainable = False\n\n    inputs = Input(shape=(240,240,3))\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    # Hyperparameter: number of units in the Dense layer\n    dense_units = hp.Int('dense_units', min_value=64, max_value=256, step=32, default=128)\n    x = Dense(dense_units, activation='relu')(x)\n    # Hyperparameter: dropout rate\n    dropout_rate = hp.Float('dropout', 0.2, 0.5, step=0.1, default=0.5)\n    x = Dropout(dropout_rate)(x)\n    outputs = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs, outputs)\n    # Hyperparameter: learning rate (use a smaller rate if unfreezing)\n    lr = hp.Float('lr', min_value=1e-5, max_value=1e-3, sampling='LOG', default=1e-4)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Instantiate the tuner\ntuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=10,\n    executions_per_trial=1,\n    directory='my_dir',\n    project_name='DenseNet201_tuning'\n)\n\ntuner.search_space_summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:14.729238Z","iopub.execute_input":"2025-03-23T22:07:14.729500Z","iopub.status.idle":"2025-03-23T22:07:20.182380Z","shell.execute_reply.started":"2025-03-23T22:07:14.729476Z","shell.execute_reply":"2025-03-23T22:07:20.181379Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nSearch space summary\nDefault search space size: 4\nunfreeze (Boolean)\n{'default': True, 'conditions': []}\ndense_units (Int)\n{'default': 128, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\ndropout (Float)\n{'default': 0.5, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\nlr (Float)\n{'default': 0.0001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.001, 'step': None, 'sampling': 'log'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell 8: Run the hyperparameter search on the training dataset.\nsteps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\nEPOCHS = 10\n\ntuner.search(\n    train_ds,\n    epochs=EPOCHS,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=val_ds,\n    class_weight=class_weights\n)\n\n# Get the best hyperparameters.\nbest_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\nprint(\"✅ Best hyperparameters found:\")\nprint(best_hp.values)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:07:20.184874Z","iopub.execute_input":"2025-03-23T22:07:20.185157Z","iopub.status.idle":"2025-03-24T07:27:35.042521Z","shell.execute_reply.started":"2025-03-23T22:07:20.185136Z","shell.execute_reply":"2025-03-24T07:27:35.041601Z"}},"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 59m 22s]\nval_accuracy: 0.7820873260498047\n\nBest val_accuracy So Far: 0.8369870781898499\nTotal elapsed time: 09h 20m 15s\n✅ Best hyperparameters found:\n{'unfreeze': True, 'dense_units': 64, 'dropout': 0.2, 'lr': 0.00030039157763138153}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Cell 9: Build the model with the best hyperparameters from the tuner.\nbest_model = tuner.hypermodel.build(best_hp)\nbest_model.summary()\n\n# Train this model with the frozen base.\nhistory = best_model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=val_ds,\n    callbacks=[EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n               ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)],\n    class_weight=class_weights\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T07:27:35.043866Z","iopub.execute_input":"2025-03-24T07:27:35.044199Z","iopub.status.idle":"2025-03-24T07:27:37.947895Z","shell.execute_reply.started":"2025-03-24T07:27:35.044166Z","shell.execute_reply":"2025-03-24T07:27:37.946791Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ densenet201 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1920\u001b[0m)          │      \u001b[38;5;34m18,321,984\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m122,944\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ densenet201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">122,944</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,444,993\u001b[0m (70.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,444,993</span> (70.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,215,937\u001b[0m (69.49 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,215,937</span> (69.49 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m229,056\u001b[0m (894.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">229,056</span> (894.75 KB)\n</pre>\n"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-3fea35b8fede>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     callbacks=[EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n\u001b[0m\u001b[1;32m     12\u001b[0m                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)],\n\u001b[1;32m     13\u001b[0m     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"],"ename":"NameError","evalue":"name 'EarlyStopping' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"# Cell 10: Clone the frozen-base model for later evaluation.\nmodel_frozen = tf.keras.models.clone_model(best_model)\nmodel_frozen.build((None, 240,240,3))\nmodel_frozen.set_weights(best_model.get_weights())\nprint(\"✅ Frozen-base model cloned.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T07:27:37.948285Z","iopub.status.idle":"2025-03-24T07:27:37.948526Z","shell.execute_reply":"2025-03-24T07:27:37.948429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Unfreeze the base layers for fine-tuning.\n# Here we unfreeze all layers; alternatively, you can partially unfreeze.\nfrom tensorflow.keras.optimizers import Adam\n\nbase_model = best_model.layers[0]  # Assuming the base model is the first layer in the Sequential model.\nbase_model.trainable = True\n\n# Recompile with a lower learning rate for fine-tuning.\nbest_model.compile(optimizer=Adam(learning_rate=1e-5),\n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\nprint(\"✅ Base model layers unfrozen for fine-tuning.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T07:27:37.949416Z","iopub.status.idle":"2025-03-24T07:27:37.949779Z","shell.execute_reply":"2025-03-24T07:27:37.949607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12: Fine-tune the model with unfrozen base layers.\nFINE_TUNE_EPOCHS = 10\n\nfine_tune_history = best_model.fit(\n    train_ds,\n    epochs=FINE_TUNE_EPOCHS,\n    steps_per_epoch=steps_per_epoch,\n    validation_data=val_ds,\n    callbacks=[EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n               ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)],\n    class_weight=class_weights\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T07:27:37.950567Z","iopub.status.idle":"2025-03-24T07:27:37.950863Z","shell.execute_reply":"2025-03-24T07:27:37.950748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 13: Evaluate the frozen-base and fine-tuned models using evaluation metrics and plot ROC curves.\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n\ndef evaluate_model(model, dataset, stage_name=\"\"):\n    y_true = []\n    y_pred = []\n    y_scores = []  # Raw probabilities\n    \n    for images, labels in dataset:\n        preds = model.predict(images)\n        y_true.extend(labels.numpy())\n        y_pred.extend((preds > 0.5).astype(\"int32\").flatten())\n        y_scores.extend(preds.flatten())\n    \n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    fpr, tpr, _ = roc_curve(y_true, y_scores)\n    roc_auc = auc(fpr, tpr)\n    \n    print(f\"=== {stage_name} Model ===\")\n    print(\"Accuracy: {:.2f}%\".format(acc * 100))\n    print(\"Precision: {:.2f}\".format(prec))\n    print(\"Recall: {:.2f}\".format(rec))\n    print(\"F1-Score: {:.2f}\".format(f1))\n    print(\"Confusion Matrix:\\n\", cm)\n    print(\"AUC: {:.2f}\".format(roc_auc))\n    print()\n    \n    plt.figure(figsize=(8,6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC (AUC = {:.2f})'.format(roc_auc))\n    plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0,1.0])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'{stage_name} ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n# Evaluate the frozen-base model\nevaluate_model(model_frozen, val_ds, stage_name=\"Frozen Base\")\n\n# Evaluate the fine-tuned model (current best_model)\nevaluate_model(best_model, val_ds, stage_name=\"Fine-Tuned\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T07:27:37.951757Z","iopub.status.idle":"2025-03-24T07:27:37.952041Z","shell.execute_reply":"2025-03-24T07:27:37.951930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 14: Plot combined learning curves for accuracy and loss.\nplt.figure(figsize=(14,5))\n\n# Accuracy Plot\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Frozen Base - Train Acc')\nplt.plot(history.history['val_accuracy'], label='Frozen Base - Val Acc')\nplt.plot(fine_tune_history.history['accuracy'], label='Fine-Tuned - Train Acc')\nplt.plot(fine_tune_history.history['val_accuracy'], label='Fine-Tuned - Val Acc')\nplt.title('Accuracy over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\n\n# Loss Plot\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Frozen Base - Train Loss')\nplt.plot(history.history['val_loss'], label='Frozen Base - Val Loss')\nplt.plot(fine_tune_history.history['loss'], label='Fine-Tuned - Train Loss')\nplt.plot(fine_tune_history.history['val_loss'], label='Fine-Tuned - Val Loss')\nplt.title('Loss over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T07:27:37.953097Z","iopub.status.idle":"2025-03-24T07:27:37.953469Z","shell.execute_reply":"2025-03-24T07:27:37.953298Z"}},"outputs":[],"execution_count":null}]}