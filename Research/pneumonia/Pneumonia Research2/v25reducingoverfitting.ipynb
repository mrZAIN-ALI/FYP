{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10338,"databundleVersionId":862042,"sourceType":"competition"},{"sourceId":11219702,"sourceType":"datasetVersion","datasetId":7006735},{"sourceId":11219756,"sourceType":"datasetVersion","datasetId":7006771},{"sourceId":11219786,"sourceType":"datasetVersion","datasetId":7006792}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Import libraries and set seeds for reproducibility.\nimport os\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pydicom\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\n\n# Set seeds for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\nprint(\"✅ Libraries imported and seeds set!\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:18.733133Z","iopub.execute_input":"2025-03-31T15:41:18.733409Z","iopub.status.idle":"2025-03-31T15:41:32.728021Z","shell.execute_reply.started":"2025-03-31T15:41:18.733389Z","shell.execute_reply":"2025-03-31T15:41:32.727121Z"}},"outputs":[{"name":"stdout","text":"✅ Libraries imported and seeds set!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Load dataset metadata and split data into training and validation sets.\ndataset_path = \"/kaggle/input/rsna-pneumonia-detection-challenge\"\ntrain_labels_csv = os.path.join(dataset_path, \"stage_2_train_labels.csv\")\nclass_info_csv = os.path.join(dataset_path, \"stage_2_detailed_class_info.csv\")\n\n# Read CSV files\nlabels_df = pd.read_csv(train_labels_csv)\nclass_info_df = pd.read_csv(class_info_csv)\n\n# Merge on 'patientId' and simplify labels (0: Normal, 1: Pneumonia)\nmerged_df = pd.merge(labels_df, class_info_df, on=\"patientId\")\nlabels_simple = merged_df[['patientId', 'Target']].drop_duplicates().reset_index(drop=True)\nlabels_simple['Target'] = labels_simple['Target'].map({0: 'Normal', 1: 'Pneumonia'})\nlabels_simple['patientId'] = labels_simple['patientId'].astype(str) + \".dcm\"\n\n# Split data (80% train, 20% validation), stratified by target.\ntrain_df, val_df = train_test_split(labels_simple, test_size=0.2, random_state=SEED, stratify=labels_simple['Target'])\nprint(\"Train samples:\", len(train_df))\nprint(\"Validation samples:\", len(val_df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:32.729055Z","iopub.execute_input":"2025-03-31T15:41:32.729507Z","iopub.status.idle":"2025-03-31T15:41:32.910934Z","shell.execute_reply.started":"2025-03-31T15:41:32.729485Z","shell.execute_reply":"2025-03-31T15:41:32.910105Z"}},"outputs":[{"name":"stdout","text":"Train samples: 21347\nValidation samples: 5337\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Define a function to load and preprocess DICOM images.\ndef load_preprocess_dicom(dicom_path, img_size=(240,240)):\n    dicom_data = pydicom.dcmread(dicom_path)\n    img_array = dicom_data.pixel_array.astype(np.float32)\n    # Normalize pixel values to [0,1]\n    img_norm = (img_array - np.min(img_array)) / (np.max(img_array) - np.min(img_array) + 1e-10)\n    # Resize image\n    img_resized = cv2.resize(img_norm, img_size)\n    # Convert grayscale to 3-channel RGB\n    img_rgb = np.stack([img_resized]*3, axis=-1)\n    return img_rgb\n\n# Test the function on a sample image\nsample_image_path = os.path.join(dataset_path, \"stage_2_train_images\", train_df.iloc[0]['patientId'])\nsample_img = load_preprocess_dicom(sample_image_path)\nprint(\"✅ Sample image shape (should be 240x240x3):\", sample_img.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:32.913027Z","iopub.execute_input":"2025-03-31T15:41:32.913266Z","iopub.status.idle":"2025-03-31T15:41:33.019975Z","shell.execute_reply.started":"2025-03-31T15:41:32.913245Z","shell.execute_reply":"2025-03-31T15:41:33.019107Z"}},"outputs":[{"name":"stdout","text":"✅ Sample image shape (should be 240x240x3): (240, 240, 3)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 4: Create data generators for training and validation.\ndef data_generator(df, batch_size=64, img_size=(240,240), infinite=True):\n    def gen():\n        if infinite:\n            while True:\n                shuffled_df = df.sample(frac=1).reset_index(drop=True)\n                for _, row in shuffled_df.iterrows():\n                    patient_id = row['patientId']\n                    label = 1 if row['Target'] == 'Pneumonia' else 0\n                    dicom_path = os.path.join(dataset_path, \"stage_2_train_images\", patient_id)\n                    img = load_preprocess_dicom(dicom_path, img_size)\n                    yield img, label\n        else:\n            for _, row in df.iterrows():\n                patient_id = row['patientId']\n                label = 1 if row['Target'] == 'Pneumonia' else 0\n                dicom_path = os.path.join(dataset_path, \"stage_2_train_images\", patient_id)\n                img = load_preprocess_dicom(dicom_path, img_size)\n                yield img, label\n\n    ds = tf.data.Dataset.from_generator(\n        gen,\n        output_types=(tf.float32, tf.int32),\n        output_shapes=((img_size[0], img_size[1], 3), ())\n    )\n    ds = ds.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return ds\n\nBATCH_SIZE = 64\ntrain_ds = data_generator(train_df, batch_size=BATCH_SIZE, img_size=(240,240), infinite=True)\nval_ds = data_generator(val_df, batch_size=BATCH_SIZE, img_size=(240,240), infinite=False)\nprint(\"✅ Data generators created with batch size:\", BATCH_SIZE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:33.021528Z","iopub.execute_input":"2025-03-31T15:41:33.021802Z","iopub.status.idle":"2025-03-31T15:41:35.555521Z","shell.execute_reply.started":"2025-03-31T15:41:33.021779Z","shell.execute_reply":"2025-03-31T15:41:35.554632Z"}},"outputs":[{"name":"stdout","text":"✅ Data generators created with batch size: 64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 5: Compute class weights to mitigate class imbalance.\ny_train = train_df['Target'].apply(lambda x: 1 if x == 'Pneumonia' else 0)\nweights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = {i: w for i, w in enumerate(weights)}\nprint(\"✅ Class weights computed:\", class_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:35.556473Z","iopub.execute_input":"2025-03-31T15:41:35.556782Z","iopub.status.idle":"2025-03-31T15:41:35.576150Z","shell.execute_reply.started":"2025-03-31T15:41:35.556750Z","shell.execute_reply":"2025-03-31T15:41:35.575255Z"}},"outputs":[{"name":"stdout","text":"✅ Class weights computed: {0: 0.6454314567333858, 1: 2.219022869022869}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\nfrom tensorflow.keras.models import Model\n\ndef build_best_model():\n    # Best hyperparameters from tuning:\n    unfreeze = True\n    dense_units = 64\n    dropout_rate = 0.3\n    lr = 0.00010733251249694184\n    \n    # Load DenseNet201 with ImageNet weights without the top classifier\n    base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(240,240,3))\n    base_model.trainable = unfreeze  # Unfreeze the base if True\n    \n    inputs = Input(shape=(240,240,3))\n    # Pass inputs through the base model; use training=False to avoid updating BatchNorm stats inadvertently.\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(dense_units, activation='relu')(x)\n    x = Dropout(dropout_rate)(x)\n    outputs = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs, outputs)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\nbest_model = build_best_model()\nbest_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:35.576977Z","iopub.execute_input":"2025-03-31T15:41:35.577295Z","iopub.status.idle":"2025-03-31T15:41:41.154351Z","shell.execute_reply.started":"2025-03-31T15:41:35.577264Z","shell.execute_reply":"2025-03-31T15:41:41.153487Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ densenet201 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1920\u001b[0m)          │      \u001b[38;5;34m18,321,984\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1920\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m122,944\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ densenet201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">18,321,984</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1920</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">122,944</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,444,993\u001b[0m (70.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,444,993</span> (70.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,215,937\u001b[0m (69.49 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,215,937</span> (69.49 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m229,056\u001b[0m (894.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">229,056</span> (894.75 KB)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Set up EarlyStopping to monitor validation loss:\nearly_stopping = EarlyStopping(\n    monitor='val_loss',      # monitor the validation loss\n    patience=2,              # stop if no improvement after 2 epochs\n    restore_best_weights=True\n)\n\n# Set up ReduceLROnPlateau to lower the learning rate when the validation loss plateaus:\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',      # monitor the validation loss\n    factor=0.5,              # reduce learning rate by a factor of 0.5\n    patience=1,              # wait 1 epoch before reducing the LR\n    min_lr=1e-6              # set a minimum learning rate\n)\n\n# Now train the model with these callbacks.\nhistory_final = best_model.fit(\n    train_ds,\n    epochs=20,               # set a high max epochs; early stopping will stop training earlier if needed\n    validation_data=val_ds,\n    class_weight=class_weights,  # if you computed class weights in your earlier cells\n    callbacks=[early_stopping, reduce_lr]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T15:41:41.155214Z","iopub.execute_input":"2025-03-31T15:41:41.155491Z","iopub.status.idle":"2025-03-31T20:52:24.903025Z","shell.execute_reply.started":"2025-03-31T15:41:41.155470Z","shell.execute_reply":"2025-03-31T20:52:24.900675Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n  21715/Unknown \u001b[1m18643s\u001b[0m 838ms/step - accuracy: 0.9326 - loss: 0.1436","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4e7a66cd2840>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Now train the model with these callbacks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m history_final = best_model.fit(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0;31m# set a high max epochs; early stopping will stop training earlier if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"# # Define callbacks\n# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n\n# EPOCHS = 10\n\n# history = best_model.fit(\n#     train_ds,\n#     epochs=EPOCHS,\n#     validation_data=val_ds,\n#     callbacks=[early_stop, reduce_lr]\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.903671Z","iopub.status.idle":"2025-03-31T20:52:24.904062Z","shell.execute_reply":"2025-03-31T20:52:24.903903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_loss, val_accuracy = best_model.evaluate(val_ds)\nprint(f\"Validation Loss: {val_loss:.4f}\")\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.904930Z","iopub.status.idle":"2025-03-31T20:52:24.905415Z","shell.execute_reply":"2025-03-31T20:52:24.905263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_final=history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.906376Z","iopub.status.idle":"2025-03-31T20:52:24.906713Z","shell.execute_reply":"2025-03-31T20:52:24.906561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12 (Optional): Visualize Training History\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 5))\n\n# Plot accuracy over epochs\nplt.subplot(1, 2, 1)\nplt.plot(history_final.history['accuracy'], label='Train Accuracy')\nplt.plot(history_final.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Final Model Accuracy Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss over epochs\nplt.subplot(1, 2, 2)\nplt.plot(history_final.history['loss'], label='Train Loss')\nplt.plot(history_final.history['val_loss'], label='Validation Loss')\nplt.title('Final Model Loss Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.907329Z","iopub.status.idle":"2025-03-31T20:52:24.907670Z","shell.execute_reply":"2025-03-31T20:52:24.907518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the validation dataset\nloss, accuracy = best_model.evaluate(val_ds)\nprint(\"Validation Loss: {:.4f}\".format(loss))\nprint(\"Validation Accuracy: {:.2f}%\".format(accuracy * 100))\n\n# Import additional libraries for evaluation\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\nimport matplotlib.pyplot as plt\n\n# Get predictions from the model (y_pred_probs are probabilities)\ny_pred_probs = best_model.predict(val_ds)\n# Convert probabilities to class predictions (binary classification with threshold 0.5)\ny_pred = (y_pred_probs > 0.5).astype(int).reshape(-1)\n\n# Retrieve true labels from the val_ds dataset\ny_true = []\nfor images, labels in val_ds:\n    y_true.extend(labels.numpy())\ny_true = np.array(y_true)\n\n# Compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Compute and print the classification report (precision, recall, F1-score)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred))\n\n# Compute ROC-AUC score\nroc_auc = roc_auc_score(y_true, y_pred_probs)\nprint(\"ROC-AUC Score: {:.2f}\".format(roc_auc))\n\n# Compute ROC curve values\nfpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n\n# Plot the ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label=\"ROC curve (area = {:.2f})\".format(roc_auc))\nplt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Receiver Operating Characteristic (ROC) Curve\")\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.909054Z","iopub.status.idle":"2025-03-31T20:52:24.909388Z","shell.execute_reply":"2025-03-31T20:52:24.909246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    import matplotlib.pyplot as plt\n    \n    # Replace 'history' with the variable name returned by model.fit() if different (e.g., history_final)\n    plt.figure(figsize=(14, 5))\n    \n    # Plot Accuracy Curves\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Training vs. Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot Loss Curves\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Training vs. Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.910387Z","iopub.status.idle":"2025-03-31T20:52:24.910762Z","shell.execute_reply":"2025-03-31T20:52:24.910597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Replace 'history' with the variable name returned by model.fit() if different (e.g., history_final)\nplt.figure(figsize=(14, 5))\n\n# Plot Accuracy Curves\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training vs. Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot Loss Curves\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training vs. Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T20:52:24.911374Z","iopub.status.idle":"2025-03-31T20:52:24.911763Z","shell.execute_reply":"2025-03-31T20:52:24.911575Z"}},"outputs":[],"execution_count":null}]}